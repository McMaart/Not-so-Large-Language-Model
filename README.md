Project Sketch: Tiny Stories (working title)
1. Project Overview
  The "TinyStories" project aims to create an interactive platform that generates short children's stories using a controlled vocabulary (limit ~ 1500 words). This project will develop two different (small) Large Language models (LLM’s): one based on the transformer architecture and another using recurrent neural networks (RNNs). 
  Both models will be implemented in PyTorch. The goal is to compare the effectiveness of these models in generating coherent and creative stories that adhere to the vocabulary limitations by using appropriate evaluation criteria.
  This project is based on: “TinyStories: How Small Can Language Models Be and Still Speak Coherent English?” (Ronen Eldan, Yuanzhi Li, Microsoft Research, 2023)

3. Objectives
    •	Develop Two Language Models: Implement and train two models, a transformer and an RNN, to generate text based on a limited vocabulary and compare both models with suitable evaluation metrics.
    •	Data Efficiency: Focus on techniques that ensure efficient use of data and computational resources.
    •	Interactive Platform: Build an interface that allows users to input prompts and receive creative and “correct” story suggestions generated by the model. (correct syntax and semantics)
   
5. Technical Requirements
  Data
    •	Sources: TinyStories dataset (size: , # different word types: ,length sentences: ), data set creation with GPT 4 and limited vocabulary
    •	Preprocessing: Tokenization, vocabulary restriction, and conversion into suitable formats for model training.
  Models
    •	Transformer Model: Simplified transformer architecture suitable for handling limited vocabulary and shorter text sequences efficiently.
    •	RNN Model: Comparable RNN model (w.r.t. resources)
    •	Different Configurations, Embeddings, data?
  Software and Tools
    •	Python as the primary programming language.
    •	Pycharm as primary IDE used by developers.
    •	Jupyter Notebook for quick model analysis
    •	CustomTkinter for GUI
    •	PyTorch for implementing machine learning models.
    •	Git for version control, hosted on GitHub.
    •	Venv environments for managing dependencies and ensuring consistency across development setups. Hint: Conda does not automatically work with customtkinter

6. Project Milestones
    1.	Project Setup and Data Preparation:
      •	Set up version control
      •	Data collection and preprocessing.
      •	Initial model design and setup of development environments.
    2.	Model Development and Initial Training:
      •	Implementation and training of the transformer and RNN models.
      •	Set up basic user interface and testing.
    3.	Interface Development and Model Integration:
      •	Development of the full-featured user interface.
      •	Integration of the models with the application.
      •	Begin internal testing and iterations based on team feedback.

7. Evaluation Metrics
    •	Model Performance: Runtime, Accuracy (syntactically, semantically valid), Creativity (new outputs or how new? e.g. Cosine distance to closest example from training data)
    •	Operational Metrics: Response times, system reliability, error rates

8. Potential Challenges
    •	Model Bias and Sensitivity
    •	Data Quality and Diversity: Building a dataset that is diverse and representative while adhering to vocabulary restrictions.

7 . Resources
    •	Human Resources: Team of 3 developers
    •	Computational Resources: “Runs on Laptop”, more specific technical details can be provided once the models are trained.
